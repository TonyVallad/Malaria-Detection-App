{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration du modèle et des hyperparamètres\n",
    "\n",
    "Dans la cellule suivante, nous définissons les principaux hyperparamètres pour l'entraînement :\n",
    "- Nombre d'époques d'entraînement\n",
    "- Taille des batchs\n",
    "- Patience pour l'early stopping\n",
    "- Taux d'apprentissage\n",
    "- Choix du device (GPU/CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuration\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "patience = 3\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données et chargement du dataset\n",
    "\n",
    "- Dans la cellule suivante, nous effectuons plusieurs opérations importantes :\n",
    "- Configuration des transformations pour l'augmentation des données (redimensionnement, rotations, etc.)\n",
    "- Chargement des images et création des étiquettes\n",
    "- Split des données en ensembles d'entraînement, validation et test\n",
    "- Définition d'une classe Dataset personnalisée pour charger les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prétraitement\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((128, 128)),  # Adapté pour le CNN (entrée 128x128 → sortie 16x16 après 3 poolings)\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(30),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset path\n",
    "dataset_path = 'C:\\\\Users\\\\sebas\\\\PycharmProjects\\\\malaria\\\\data\\\\images'\n",
    "parasitized_dir = os.path.join(dataset_path, 'Parasitized')\n",
    "uninfected_dir = os.path.join(dataset_path, 'Uninfected')\n",
    "\n",
    "# Fichiers et étiquettes\n",
    "parasitized_files = [os.path.join(parasitized_dir, f) for f in os.listdir(parasitized_dir) if f.endswith('.png')]\n",
    "uninfected_files = [os.path.join(uninfected_dir, f) for f in os.listdir(uninfected_dir) if f.endswith('.png')]\n",
    "parasitized_labels = [0] * len(parasitized_files)\n",
    "uninfected_labels = [1] * len(uninfected_files)\n",
    "\n",
    "all_files = parasitized_files + uninfected_files\n",
    "all_labels = parasitized_labels + uninfected_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split des données\n",
    " \n",
    "Dans la cellule suivante, nous effectuons la séparation des données en trois ensembles :\n",
    "- Un ensemble de test (20% des données)\n",
    "- Un ensemble d'entraînement et de validation (80% des données), qui est ensuite divisé en :\n",
    "- Un ensemble d'entraînement (64% du total)\n",
    "- Un ensemble de validation (16% du total)\n",
    " \n",
    "Nous utilisons un split stratifié pour conserver les proportions de chaque classe.\n",
    "Nous définissons également une classe Dataset personnalisée pour charger les images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split stratifié test (20%)\n",
    "trainval_files, test_files, trainval_labels, test_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Split stratifié val (20% de train_val)\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    trainval_files, trainval_labels, test_size=0.2, stratify=trainval_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Dataset personnalisé\n",
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, nous définissons l'architecture de notre CNN personnalisé. Le modèle comprend :\n",
    "- 3 couches de convolution avec des filtres de taille 3x3 et un padding de 1\n",
    "- Des couches de pooling pour réduire la dimension spatiale\n",
    "- Une couche fully connected avec 128 neurones\n",
    "- Une couche de dropout pour éviter le surapprentissage \n",
    "- Une couche de sortie avec 2 neurones (classification binaire)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition d'un modèle de réseau de neurones pour classer des images (cellule malade ou saine)\n",
    "class CNNMalariaModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # On précise qu'on veut classer en 2 catégories (cellule malade ou saine)\n",
    "        super(CNNMalariaModel, self).__init__()  # Initialisation du modèle à partir de la classe de base nn.Module\n",
    "\n",
    "        # 1ère couche de convolution : elle regarde des petits morceaux de l'image grâce au kernel 3x3\n",
    "        # Elle transforme les 3 canaux de couleur (rouge, vert, bleu) en 32 \"cartes de caractéristiques\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # Normalise les valeurs pour aider le réseau à apprendre plus vite\n",
    "\n",
    "        # 2ème couche : prend les 32 cartes et en crée 64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # 3ème couche : transforme les 64 cartes en 128 cartes\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # MaxPool : réduit la taille des images de moitié à chaque fois (comme un zoom arrière)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # GAP (Global Average Pooling) : réduit chaque carte à une seule valeur moyenne\n",
    "        # Cela permet au modèle d’accepter des images de tailles différentes\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # 1ère couche entièrement connectée : prend les 128 valeurs et en fait 128 nouvelles\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "\n",
    "        # Dropout : coupe certaines connexions au hasard pendant l'entraînement (pour éviter que le réseau ne \"triche\")\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Dernière couche : donne 2 valeurs, une pour chaque classe (ex : \"malade\" et \"saine\")\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):  # C’est ici qu’on décrit comment les données traversent le réseau\n",
    "        # Étape 1 : première convolution + normalisation + activation (ReLU = garde les valeurs positives)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # Étape 2 : deuxième convolution + normalisation + activation + réduction de taille\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Étape 3 : troisième convolution + normalisation + activation + réduction de taille\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Réduction à une seule valeur par carte (grâce à GAP)\n",
    "        x = self.gap(x)  # Résultat : un petit tableau de forme [batch, 128, 1, 1]\n",
    "\n",
    "        # On \"aplatie\" ce petit tableau en une ligne pour le donner à la couche suivante\n",
    "        x = x.view(x.size(0), -1)  # Devient [batch, 128]\n",
    "\n",
    "        # Première couche complètement connectée avec ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Application du dropout (pendant l'entraînement uniquement)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Dernière couche qui donne 2 scores (un pour chaque classe)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Pas besoin d'ajouter Softmax ici : la fonction de perte CrossEntropy s'en occupe\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cellule suivante, nous créons les datasets et dataloaders pour l'entraînement, la validation et le test.\n",
    "Nous initialisons également le modèle, définissons la fonction de perte (CrossEntropyLoss) et l'optimiseur (Adam).\n",
    "Nous implémentons aussi une fonction d'évaluation qui calcule la perte et l'exactitude sur un jeu de données.\n",
    "Enfin, nous mettons en place la boucle d'entraînement avec early stopping pour éviter le surapprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datasets & Loaders\n",
    "train_dataset = MalariaDataset(train_files, train_labels, transform=transform_train)\n",
    "val_dataset = MalariaDataset(val_files, val_labels, transform=transform_train)\n",
    "test_dataset = MalariaDataset(test_files, test_labels, transform=transform_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modèle\n",
    "model = CNNMalariaModel().to(device)\n",
    "\n",
    "# Loss et optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'évaluation\n",
    "Dans la cellule suivante, nous définissons une fonction d'évaluation `evaluate()` qui permet de calculer la perte et l'exactitude du modèle sur un jeu de données donné. Cette fonction sera utilisée pour évaluer les performances du modèle sur les ensembles de validation et de test. Elle prend en paramètres le modèle et un dataloader, et retourne la perte moyenne et le pourcentage de prédictions correctes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return running_loss / len(dataloader), 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables pour l'entraînement\n",
    "- best_acc : stocke la meilleure exactitude obtenue sur l'ensemble de validation\n",
    "- patience_counter : compte le nombre d'époques sans amélioration pour l'early stopping\n",
    "- best_model_state : sauvegarde l'état du meilleur modèle\n",
    "Nous créons également un dossier 'models' pour sauvegarder les checkpoints du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entraînement\n",
    "best_acc = 0.0\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "os.makedirs('models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du modèle. Pour chaque époque :\n",
    "- Nous calculons la perte et l'exactitude sur l'ensemble d'entraînement\n",
    "- Nous évaluons le modèle sur l'ensemble de validation\n",
    "- Nous sauvegardons le meilleur modèle si l'exactitude de validation s'améliore\n",
    "- Nous appliquons l'early stopping si aucune amélioration n'est constatée pendant plusieurs époques\n",
    "Une barre de progression tqdm affiche l'avancement de l'entraînement avec les métriques en temps réel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/20]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/552 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 552/552 [04:15<00:00,  2.16it/s, loss=1.0172, acc=82.42%]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "    print('-' * 50)\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    print(f'\\nEpoch terminé: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_state = model.state_dict()\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': best_model_state,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "        }, 'models/best_model_cnn.pth')\n",
    "        print(f'✅ Nouveau meilleur modèle sauvegardé avec une Val Acc de {best_acc:.2f}%')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Patience: {patience_counter}/{patience}')\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\n⏹️ Early stopping après {epoch + 1} epochs sans amélioration.')\n",
    "            break\n",
    "\n",
    "# Évaluation finale\n",
    "print(\"\\n📊 Évaluation finale sur le test set :\")\n",
    "model.load_state_dict(best_model_state)\n",
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
