{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 align=\"center\">Malaria Detection - PyTorch</h1>**\n",
    "\n",
    "<p align=\"center\"><i>V1.2 - Added Device Selection</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip installs & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install torch torchvision\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data download\n",
    "import kagglehub\n",
    "\n",
    "# For data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For deep learning (PyTorch)\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Miscellaneous / Utilities\n",
    "import random\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  # Resize all images to defined size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "VALIDATION_SIZE = 0.2\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Device selection\n",
    "DEVICE = 'GPU'  # Options: 'TPU', 'GPU', 'CPU'\n",
    "\n",
    "# Data source selection\n",
    "SOURCE = 'kaggle'\n",
    "# DATA_DIR = kagglehub.dataset_download('iarunava/cell-images-for-detecting-malaria', download_dir='src/static/data/') # Download from Kaggle\n",
    "# DATA_DIR = 'src/static/data/downloads/extracted/ZIP.data.lhnc.nlm.nih.gov_publ_Mala_cell_imagCpSVVrJBQVm1EAGSYJgFN2ZUxCZtjRh76bGSL61Dxmg.zip/cell_images' # Local\n",
    "# DATA_DIR = '/kaggle/input/cell-images-for-detecting-malaria' # Colab\n",
    "DATA_DIR = 'src/static/data'\n",
    "\n",
    "MODEL_DIR = \"src/static/model/\"\n",
    "# MODEL_NAME = 'model.keras'\n",
    "MODEL_NAME = 'best_model.pt'\n",
    "MODEL_PATH = MODEL_DIR + MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape codes for colored output\n",
    "GREEN = \"\\033[92m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "RED = \"\\033[91m\"\n",
    "RESET = \"\\033[0m\"  # White"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mUsing device: \u001b[0mCPU (fallback)\n"
     ]
    }
   ],
   "source": [
    "# Device selector\n",
    "if DEVICE.upper() == 'TPU':\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        device = xm.xla_device()\n",
    "        actual_device = 'TPU'\n",
    "    except ImportError:\n",
    "        raise ImportError(\"TPU support requires torch_xla. Make sure you're running on a TPU environment like Google Colab.\")\n",
    "elif DEVICE.upper() == 'GPU':\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        actual_device = 'GPU'\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        actual_device = 'CPU (fallback)'\n",
    "elif DEVICE.upper() == 'CPU':\n",
    "    device = torch.device('cpu')\n",
    "    actual_device = 'CPU'\n",
    "else:\n",
    "    raise ValueError(\"Invalid DEVICE value. Choose from: 'TPU', 'GPU', 'CPU'.\")\n",
    "\n",
    "print(f\"{YELLOW}Using device: {RESET}{actual_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mSkipping existing folder: \u001b[0msrc/static/data\\Parasitized\n",
      "\u001b[93mSkipping existing folder: \u001b[0msrc/static/data\\Uninfected\n",
      "\n",
      "\u001b[93mData source:\u001b[0m\n",
      "src/static/data\n",
      "\n",
      "\u001b[93mLabels found:\u001b[0m\n",
      "['Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "if SOURCE == 'kaggle':\n",
    "    # Download dataset\n",
    "    downloaded_path = kagglehub.dataset_download('iarunava/cell-images-for-detecting-malaria')\n",
    "\n",
    "    # This is where the actual images live\n",
    "    source_path = os.path.join(downloaded_path, 'cell_images')\n",
    "\n",
    "    # Sanity check: skip top-level duplicates\n",
    "    top_level_dupes = ['Parasitized', 'Uninfected']\n",
    "    for folder in top_level_dupes:\n",
    "        dupe_path = os.path.join(downloaded_path, folder)\n",
    "        if os.path.exists(dupe_path):\n",
    "            print(f\"{YELLOW}Skipping top-level duplicate: {RESET}{dupe_path}\")\n",
    "\n",
    "    # Ensure target directory exists\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "    # Clean up nested 'cell_images' in the target dir if it already exists\n",
    "    nested_path = os.path.join(DATA_DIR, 'cell_images')\n",
    "    if os.path.exists(nested_path):\n",
    "        print(f\"{YELLOW}Removing nested folder: {RESET}{nested_path}\")\n",
    "        shutil.rmtree(nested_path)\n",
    "\n",
    "    # Define allowed folders to copy (explicitly skip weird ones)\n",
    "    allowed_folders = ['Parasitized', 'Uninfected']\n",
    "\n",
    "    # Only copy those two\n",
    "    for folder in allowed_folders:\n",
    "        src_folder = os.path.join(source_path, folder)\n",
    "        dst_folder = os.path.join(DATA_DIR, folder)\n",
    "        if os.path.isdir(src_folder):\n",
    "            if not os.path.exists(dst_folder):\n",
    "                print(f\"{YELLOW}Copying {RESET}{folder} {YELLOW}to {RESET}{dst_folder}\")\n",
    "                shutil.copytree(src_folder, dst_folder)\n",
    "            else:\n",
    "                print(f\"{YELLOW}Skipping existing folder: {RESET}{dst_folder}\")\n",
    "# elif SOURCE == 'local':\n",
    "#     DATA_DIR = DATA_DIR + '/cell_images/'\n",
    "else:\n",
    "    raise ValueError(\"Invalid SOURCE value. Choose from: 'kaggle', 'local'\")\n",
    "\n",
    "print(f\"\\n{YELLOW}Data source:{RESET}\")\n",
    "print(DATA_DIR)\n",
    "\n",
    "print(f\"\\n{YELLOW}Labels found:{RESET}\")\n",
    "print(os.listdir(DATA_DIR))\n",
    "# print(os.listdir(DATA_DIR + '/cell_images/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4048c86251504ea2bd6499175066561d82f05ac",
    "id": "glDzwExLvYvs",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTransforms Defined.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define your transforms for the training, validation, and testing sets\n",
    "\n",
    "# Custom transform for adding Gaussian noise\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std})\"\n",
    "\n",
    "# Train/Validation/Test Transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(contrast=0.5),  # Random contrast\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0., 0.02),            # Add noise\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(f\"{GREEN}Transforms Defined.{RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "693a80046f72af973f371188ef4f5f68337c5e45",
    "id": "2XgT29JUvYvt"
   },
   "source": [
    "## Load Dataset and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "_uuid": "86969405320d0d0cfce4634d61559f8e513fd1f8",
    "id": "Tt48gAHdvYvu",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mData loaded and transformed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_dir=DATA_DIR\n",
    "train_data = datasets.ImageFolder(img_dir,transform=train_transforms)\n",
    "\n",
    "print(f\"{GREEN}Data loaded and transformed.{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "_uuid": "7955aca66f96447427238e32459b010a9459e674",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742982955420,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "sAnSUO_lvYvx",
    "outputId": "07011334-09f7-4195-bf57-2a720df9ade2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTotal length:\u001b[0m\n",
      "27558\n",
      "\n",
      "\u001b[92mTrain length:\u001b[0m\n",
      "19291\n",
      "\n",
      "\u001b[93mValidation length:\u001b[0m\n",
      "5511\n",
      "\n",
      "\u001b[93mTest length:\u001b[0m\n",
      "2756\n"
     ]
    }
   ],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# Percentage of training set to use as test\n",
    "test_size = 0.1\n",
    "\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "valid_split = int(np.floor((valid_size) * num_train))\n",
    "test_split = int(np.floor((valid_size+test_size) * num_train))\n",
    "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
    "\n",
    "print(f\"{BLUE}Total length:{RESET}\")\n",
    "print(num_train)\n",
    "print(f\"\\n{GREEN}Train length:{RESET}\")\n",
    "print(len(train_idx))\n",
    "print(f\"\\n{YELLOW}Validation length:{RESET}\")\n",
    "print(len(valid_idx))\n",
    "print(f\"\\n{YELLOW}Test length:{RESET}\")\n",
    "print(len(test_idx))\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50041f842e818a4cb38665cafc8bdc36798e97e3",
    "id": "1V3EGYX3vYvy"
   },
   "source": [
    "## Model ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "_uuid": "fb07bd7c2f161ffc78cb09d5107b7f3350f62f1b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1742982956947,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "iNGT6s6OvYvz",
    "outputId": "a5611259-4281-4668-8232-3ef3eeef4f94",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mModel loaded.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 2, bias=True)\n",
    "\n",
    "fc_parameters = model.fc.parameters()\n",
    "\n",
    "for param in fc_parameters:\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(f\"{GREEN}Model loaded.{RESET}\\n\")\n",
    "\n",
    "# model # Display Model details - comment out if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "_uuid": "055d00bdda33b6d49645f94cd83109439e0cd238",
    "id": "oJiHzu5_vYv2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mCross entropy loss and SGD optimizer loaded.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if actual_device == 'GPU': # See later if I can relocate this to Model selection\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001 , momentum=0.9)\n",
    "\n",
    "print(f\"{GREEN}Cross entropy loss and SGD optimizer loaded.{RESET}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff47e88ab79c7bde1cefd3c2ea97fa177010f5a1",
    "id": "tQF9a714vYv2"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a256dad508dc7acd182e1df6faad1287d540b842",
    "id": "qzL0vYhwvYv3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, model, optimizer, criterion, use_cuda, save_path, patience=5):\n",
    "    \"\"\"Train model with early stopping, tqdm, and accuracy tracking.\"\"\"\n",
    "\n",
    "    valid_loss_min = np.inf\n",
    "    epochs_no_improve = 0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"{YELLOW}Epoch {RESET}{epoch}/{n_epochs} [{YELLOW}Training{RESET}]\", leave=False)\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_tqdm):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "\n",
    "            # Accuracy\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct_train += (predicted == target).sum().item()\n",
    "            total_train += target.size(0)\n",
    "\n",
    "            train_loader_tqdm.set_postfix(loss=train_loss.item())\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loader_tqdm = tqdm(valid_loader, desc=f\"{GREEN}Epoch {RESET}{epoch}/{n_epochs} [{GREEN}Validation{RESET}]\", leave=False)\n",
    "\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader_tqdm):\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "                # Accuracy\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct_val += (predicted == target).sum().item()\n",
    "                total_val += target.size(0)\n",
    "\n",
    "                valid_loader_tqdm.set_postfix(val_loss=valid_loss.item())\n",
    "\n",
    "        # Accuracy calculations\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        \n",
    "        # Save stats\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(valid_loss.item())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Print stats\n",
    "        print(f\"{GREEN}Epoch: {RESET}{epoch} \"\n",
    "              f\"\\t{BLUE}Train Loss: {RESET}{train_loss:.6f} | {BLUE}Train Acc: {RESET}{train_accuracy:.2f}% \"\n",
    "              f\"\\t{BLUE}Val Loss: {RESET}{valid_loss:.6f} | {BLUE}Val Acc: {RESET}{val_accuracy:.2f}%\")\n",
    "\n",
    "        ########################\n",
    "        # early stopping check #\n",
    "        ########################\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"{YELLOW}Validation loss decreased {RESET}({valid_loss_min:.6f} --> {valid_loss:.6f}). {YELLOW}Saving model...{RESET}\\n\")\n",
    "            valid_loss_min = valid_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_wts = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"{YELLOW}No improvement in validation loss for {epochs_no_improve} epoch(s).{RESET}\\n\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\n{YELLOW}Early stopping triggered after {patience} epochs with no improvement.{RESET}\")\n",
    "            break\n",
    "\n",
    "    if best_model_wts:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mUsing device: \u001b[0mCPU (fallback)\n"
     ]
    }
   ],
   "source": [
    "# Display selected device\n",
    "print(f\"{YELLOW}Using device: {RESET}{actual_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a555ea1d6f11757caac6efb04d89828feaacd62",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 1748547,
     "status": "error",
     "timestamp": 1742984705515,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "8NG7zoZ-vYv4",
    "outputId": "833e0a61-8373-4638-9cdb-010beefbcd1d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  0s/it, loss=0.715]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[290], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start Model Training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# train(25, model, optimizer, criterion, use_cuda, 'malaria_detection.pt') # Old Model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# trained_model = train(25, model, optimizer, criterion, use_cuda, save_path=MODEL_PATH, patience=3)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model, train_losses, val_losses, train_acc, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[288], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(n_epochs, model, optimizer, criterion, use_cuda, save_path, patience)\u001b[0m\n\u001b[0;32m     28\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 31\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:154\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m--> 154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\Documents\\GitHub Repos\\Malaria-Detection-App\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check if folder exists, and create it if it doesn't\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    print(f\"{YELLOW}Created directory: {RESET}{MODEL_DIR}\\n\")\n",
    "else:\n",
    "    print(f\"{YELLOW}Directory already exists: {RESET}{MODEL_DIR}\\n\")\n",
    "\n",
    "# Start Model Training\n",
    "# train(25, model, optimizer, criterion, use_cuda, 'malaria_detection.pt') # Old Model\n",
    "# trained_model = train(25, model, optimizer, criterion, use_cuda, save_path=MODEL_PATH, patience=3)\n",
    "\n",
    "model, train_losses, val_losses, train_acc, val_acc = train(\n",
    "    n_epochs=25,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    use_cuda=use_cuda,\n",
    "    save_path=MODEL_PATH,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(train_losses, val_losses, train_acc, val_acc):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    ax1.plot(epochs, train_losses, label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, label='Validation Loss')\n",
    "    ax1.set_title('Loss over Epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Accuracy plot\n",
    "    ax2.plot(epochs, train_acc, label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "    ax2.set_title('Accuracy over Epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_training_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[276], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_training_metrics\u001b[49m(train_losses, val_losses, train_acc, val_acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_training_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Display training metrics\n",
    "plot_training_metrics(train_losses, val_losses, train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/scratchpad/notebookc948bd59fc.5d125fc5-0b92-438c-b2d8-02a553c024b7.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250326/auto/storage/goog4_request&X-Goog-Date=20250326T091653Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=843c05d980a818f9b6b120b6db62f6df87414b328bc597e71424088a75965f94b4db536bd6120d8be0dc335ccea339f28d8a1955232450613733ce296ea1b84209b96ddb372359c696f489f869f7c226fd5f2989ba795d046f063aabc420538e600d6de3e085583eafea5a3bc9bf37760744a80318169479d3d999ed2966b0d4933ceda491ca82b299f3b4a2c271e40afd937bdc06eecabe18835a58357677a21a7df2dee928151de00794f761ba34f7d76a43acf22ab9373490f9d077e54e832176ab05605746e3d2fea2fe4f70ecdfd5d2c535ef5b57d54211fc7d0e63be2efdb05b58cc21011ed4294176312e7492a464e3d732b0045a87229f458ce437ad",
     "timestamp": 1742984789044
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 87153,
     "sourceId": 200743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 19667,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
